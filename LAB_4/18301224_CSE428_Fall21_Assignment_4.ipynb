{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "18301224_CSE428_Fall21_Assignment_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwV8CXxIzjIX"
      },
      "source": [
        "# **Assignment 4**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NAME = \"Minhajul Abedin\"\n",
        "ID = \"18301224\"\n",
        "COLLABORATORS_ID = [\"\", \"\"]"
      ],
      "metadata": {
        "id": "Yy_-VXXW7BiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA-ge4vIzspK"
      },
      "source": [
        "In this assignment you will have to create the VGG-19 network from scratch, using the keras functional API and explore its usage for different tasks. [(The Functional API).](https://www.tensorflow.org/guide/keras/functional)\n",
        "[Going through the *Setup* and *Introduction* sections of the previous tutorial will suffice if you haven't attended the live demo sessions.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFT2muZmz84T"
      },
      "source": [
        "Read the VGG paper: [Very Deep Convolutional Networks for Large-Scale Image Recognition - Karen Simonyan, Andrew Zisserman](https://arxiv.org/abs/1409.1556) and complete the following tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7QX686O2icE"
      },
      "source": [
        "## Task 1\n",
        "\n",
        "Complete the following block to create a VGG19 network suitable for the ILSVRC classification task in keras and print the network's summary. (You don't have to train the network.)\n",
        "\n",
        "[Hint: __Section 2 CONVNET CONFIGURATIONS__ of the paper contains necessary information about the network architecture of the VGG network. (Column E of Table 1 is the VGG19 network architecture.)]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZCyRSG7zhDW"
      },
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhUGnfjS4GxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "558a09cc-a553-4175-8b7c-716026897191"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(224, 224, 3), name='input_1')\n",
        "\n",
        "# block-1\n",
        "x = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu', name = 'block1_conv1')(inputs)\n",
        "x=tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu', name = 'block1_conv2')(x)\n",
        "block_1_output = tf.keras.layers.MaxPooling2D(2, name = 'block1_pool')(x)\n",
        "\n",
        "# block-2\n",
        "x = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu', name = 'block2_conv1')(block_1_output)\n",
        "x=tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu', name = 'block2_conv2')(x)\n",
        "block_2_output = tf.keras.layers.MaxPooling2D(2, name = 'block2_pool')(x)\n",
        "\n",
        "# block-3\n",
        "x = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu',  name = 'block3_conv1')(block_2_output)\n",
        "x=tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu', name = 'block3_conv2')(x)\n",
        "x=tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu', name = 'block3_conv3')(x)\n",
        "x=tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu', name = 'block3_conv4')(x)\n",
        "block_3_output = tf.keras.layers.MaxPooling2D(2, name = 'block3_pool')(x)\n",
        "\n",
        "# block-4\n",
        "x = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', name = 'block4_conv1')(block_3_output)\n",
        "x=tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', name = 'block4_conv2')(x)\n",
        "x=tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', name = 'block4_conv3')(x)\n",
        "x=tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', name = 'block4_conv4')(x)\n",
        "block_4_output = tf.keras.layers.MaxPooling2D(2, name = 'block4_pool')(x)\n",
        "\n",
        "# block-5\n",
        "x = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', name = 'block5_conv1')(block_4_output)\n",
        "x=tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', name = 'block5_conv2')(x)\n",
        "x=tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', name = 'block5_conv3')(x)\n",
        "x=tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', name = 'block5_conv4')(x)\n",
        "block_5_output = tf.keras.layers.MaxPooling2D(2, name = 'block5_pool')(x)\n",
        "\n",
        "flatten = tf.keras.layers.Flatten(name='flatten')(block_5_output)\n",
        "fc1 = tf.keras.layers.Dense(4096, activation=\"relu\", name='fc1')(flatten)\n",
        "fc2 = tf.keras.layers.Dense(4096, activation=\"relu\", name='fc2')(fc1)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(1000, activation=\"softmax\", name='predictions')(fc2)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"vgg19\")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 143,667,240\n",
            "Trainable params: 143,667,240\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYOHfws84la6"
      },
      "source": [
        "Your summary should match the following:\n",
        "```\n",
        "Model: \"vgg19\"\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
        "_________________________________________________________________\n",
        "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
        "_________________________________________________________________\n",
        "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
        "_________________________________________________________________\n",
        "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
        "_________________________________________________________________\n",
        "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
        "_________________________________________________________________\n",
        "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
        "_________________________________________________________________\n",
        "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
        "_________________________________________________________________\n",
        "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
        "_________________________________________________________________\n",
        "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
        "_________________________________________________________________\n",
        "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
        "_________________________________________________________________\n",
        "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
        "_________________________________________________________________\n",
        "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
        "_________________________________________________________________\n",
        "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
        "_________________________________________________________________\n",
        "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
        "_________________________________________________________________\n",
        "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
        "_________________________________________________________________\n",
        "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
        "_________________________________________________________________\n",
        "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
        "_________________________________________________________________\n",
        "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
        "_________________________________________________________________\n",
        "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
        "_________________________________________________________________\n",
        "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
        "_________________________________________________________________\n",
        "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
        "_________________________________________________________________\n",
        "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
        "_________________________________________________________________\n",
        "flatten (Flatten)            (None, 25088)             0         \n",
        "_________________________________________________________________\n",
        "fc1 (Dense)                  (None, 4096)              102764544 \n",
        "_________________________________________________________________\n",
        "fc2 (Dense)                  (None, 4096)              16781312  \n",
        "_________________________________________________________________\n",
        "predictions (Dense)          (None, 1000)              4097000   \n",
        "=================================================================\n",
        "Total params: 143,667,240\n",
        "Trainable params: 143,667,240\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjtSv3A_76CY"
      },
      "source": [
        "## Task 2\n",
        "\n",
        "What percentage of total parameters are in the fully connected layers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eBK6yk08K5w"
      },
      "source": [
        "**Answer:** Total parameters $= 143667240 $  \n",
        "Total parameters in fully connected layers: (fc1 + fc2 + predictions)\n",
        "\\begin{align}\n",
        "&= 102764544 + 16781312 + 409700\\\\\n",
        "&= 123642856\n",
        "\\end{align}\n",
        "Percentage of total parameters are in the fully connected layers:\n",
        "\\begin{align}\n",
        "=&\\left(\\frac{123642856}{143667240} \\times 100\\right)\\%\\\\\n",
        "=&\\;86.0619\\%â‰ˆ 86.06\\%\n",
        "\\end{align}\n",
        "In the whole architecture, 86.06% of the parameters are from fully connected layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT3xbCIM8N4J"
      },
      "source": [
        "## Task 3\n",
        "\n",
        "The VGG19 network from task 1 contains a Dense (FC) output layer with 1000 units for the ILSVRC classification task. How could you modify the current output layer so that it is capable of classifying the CIFAR-100 dataset, which has a total number of 100 classes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4qnBvly9YSo"
      },
      "source": [
        "**Answer:** For the ILSVRC classification task, we keep 1000 as units in output layer as the dataset include 1000 classes. Here, units is the first parameter of Dense method which determine dimensionality of output space. The code is:\n",
        "\n",
        "\n",
        "```\n",
        "outputs = tf.keras.layers.Dense(1000, activation=\"softmax\", name='predictions')(fc2)\n",
        "```\n",
        "\n",
        "Now, for CIFAR-100 dataest we have only 100 classes. Therefore, in the output layer there will be 100 units for 100 classes. We can do that by only changing the first parameter (units) value from 1000 to 100. The code will be:\n",
        "```\n",
        "outputs = tf.keras.layers.Dense(100, activation=\"softmax\", name='predictions')(fc2)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXzTjgfT9ajY"
      },
      "source": [
        "##Task 4\n",
        "\n",
        "The VGG19 network from task 1 was designed for the ILSVRC classification challenge, but as we know there was a seperate challenge for image localisation. How could you modify the current ouput layer so that is suitable for the ILSVRC localisation task?\n",
        "\n",
        "[Hint: __Section A LOCALISATION__ contains information about the localisation task.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEjY7PL1DfuY"
      },
      "source": [
        "**Answer:** In the localisation task, a bounding box identifies the objects in the picture. Moreover, a bounding box will be represnted by its center coordinates(x, y), height and width. Thus, the output layer should be a 4-D vector which store the center coordinates, width, and height of the bounding box. There are two option available, one is single-class regression (SCR) where the bounding box prediction is shared across all classes. Another one is per-class regression (PCR) which is class specipic. In SCR the output layer will be 4-D. In contrast, for PCR 4000-D (4 x 1000) as there are 1000 classes in ILSVRC dataset.\n",
        "\n",
        "In case of SCR, the output layer will be:\n",
        "\n",
        "```\n",
        "outputs = tf.keras.layers.Dense(4, activation=\"softmax\", name='predictions')(fc2)\n",
        "```\n",
        "\n",
        "\n",
        "I will choose PCR as according to the authors of the paper it has outperformed the SCR. The output layer will be:\n",
        "\n",
        "```\n",
        "outputs = tf.keras.layers.Dense(4000, activation=\"softmax\", name='predictions')(fc2)\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLRO3JhR9c2Q"
      },
      "source": [
        "## Task 5\n",
        "\n",
        "The VGG19 network from task 1 was designed for the ILSVRC classification challenge. Explain how the authors proposed this deep network as a feature extractor for other computer vision tasks.\n",
        "[Hint: __B GENERALISATION OF VERY DEEP FEATURES__ contains information about using the VGG network as a feature extractor.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6AwIA2SDh54"
      },
      "source": [
        "**Answer:** The authors utialize their proposed deep network ConvNets which is pre trained on ILSVRC as a feature extractor on other smaller datasets where training large model from scratch is not feasible due to over-fitting because deep image represantations that learnt on ILSVRC genralise well to other datasets. To make this happen, they remove the last fully connected layer or output layer from the pre-trained ConvNet on ILSVRC. Instead of this output layer, they use 4096-D activations of the penultimate layer as image features.The image descriptor that results is L2-normalized and paired with a linear SVM classifier that has been trained on the target dataset. Also, pre-trained ConvNet weights are kept constant for simplicity while no fine-tuning is performed. \n",
        "\n",
        "The aggregation of features gathered from vaious places and sizes and carried out in a similiar manner to the ILSVRC evaluation procedure. Then, the network densely applied over the scaled image plane. After that, they performed global average pooling that produce 4096-D image descriptor which then averaged with the descriptor of horizontally flipped image. However, as evalutaion over multi-scale is beneficial, they extract feature over several scale. Finally, the resulting multi-scale features can be either stacked or pooled across scale where stacking teaches a future classifier how to mix picture statistics appropriately across a variety of scales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5zgyOw8BJ-4"
      },
      "source": [
        "### --THE END--"
      ]
    }
  ]
}